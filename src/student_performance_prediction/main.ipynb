{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e83dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b60c27",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab92597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/StudentPerformanceFactors.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2880409",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04205139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49108f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = df.dtypes[df.dtypes == 'object'].index.to_list()\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3306a088",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical:\n",
    "    df[col] = df[col].str.lower().str.replace(' ', '_').str.strip()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68f6d65",
   "metadata": {},
   "source": [
    "Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1386e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of exam_score\n",
    "plt.hist(df['exam_score'], bins=20)\n",
    "\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with NaN values\n",
    "df.isna().sum()[df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6eda3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size and % of records with NaN data\n",
    "nan_records = int(((df['teacher_quality'].isna()) | (df['parental_education_level'].isna()) | (df['distance_from_home'].isna())).sum())\n",
    "nan_records, nan_records/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b437cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical:\n",
    "    if df[col].isna().sum() > 0:\n",
    "        print(col)\n",
    "        mean_scores = df.groupby(col)['exam_score'].mean().sort_values()\n",
    "        print(mean_scores)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5edb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FaFrom your visualization, the mean exam scores for each teacher_quality level (low, medium, high) are very close to one another — all around 67–68. That tells us that this feature currently has little to no differentiating power on exam score (at least in the mean).\n",
    "\n",
    "# Given that:\n",
    "\n",
    "# The differences between categories are all around between 66-68, and\n",
    "# Only ~3.5% of records are missing,\n",
    "\n",
    "# It’s perfectly reasonable (and safe) to replace the NaN values with \"Unknown\" in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e24810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN with \"Unknown\"\n",
    "df = df.fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6682f9",
   "metadata": {},
   "source": [
    "Setting up the validation framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2056d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3fa423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90db13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7249da14",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['exam_score']\n",
    "y_val = df_val['exam_score']\n",
    "y_test = df_test['exam_score']\n",
    "\n",
    "del df_train['exam_score']\n",
    "del df_val['exam_score']\n",
    "del df_test['exam_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d201d",
   "metadata": {},
   "source": [
    "Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fffa7e",
   "metadata": {},
   "source": [
    "a. Average ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeae2ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_score = df_full_train['exam_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0609257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "for c in categorical:\n",
    "    print(c)\n",
    "    df_group = df_full_train.groupby(c)['exam_score'].agg(['mean', 'count'])\n",
    "    df_group['diff'] = df_group['mean'] - average_score\n",
    "    df_group['ratio'] = df_group['mean'] / average_score\n",
    "    display(df_group)\n",
    "    print()\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4573d9e5",
   "metadata": {},
   "source": [
    "b. Mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795fbb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4972b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_info_churn_score(series):\n",
    "    return mutual_info_score(series, df_full_train['exam_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb3747",
   "metadata": {},
   "outputs": [],
   "source": [
    "mi = df_full_train[categorical].apply(mutual_info_churn_score)\n",
    "mi.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d872103a",
   "metadata": {},
   "source": [
    "c. Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f657d095",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = [x for x in df_full_train.columns if x not in categorical + ['exam_score']]\n",
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af6185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train[numerical].corrwith(df_full_train['exam_score']).abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf9062b",
   "metadata": {},
   "source": [
    "One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac89548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47757892",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "full_train_dict = df_full_train[categorical + numerical].to_dict(orient='records')\n",
    "X_full_train = dv.transform(full_train_dict)\n",
    "\n",
    "test_dict = df_test[categorical + numerical].to_dict(orient='records')\n",
    "X_test = dv.transform(test_dict)\n",
    "\n",
    "y_full_train = df_full_train['exam_score']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf339fc",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27b39ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4067b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9afcdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(X_val)\n",
    "lr_rmse = root_mean_squared_error(y_val, y_pred)\n",
    "lr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5547248",
   "metadata": {},
   "outputs": [],
   "source": [
    "student = df_test.loc[15].to_dict()\n",
    "\n",
    "X_student = dv.transform(student)\n",
    "predicted_score = lr_model.predict(X_student)\n",
    "y_test[15], predicted_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab5dcb3",
   "metadata": {},
   "source": [
    "Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e447f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f1956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for d in [1, 2, 3, 4, 5, 6, 10, 15, 20, None]:\n",
    "    dtr_model = DecisionTreeRegressor(max_depth=d, random_state=1)\n",
    "    dtr_model.fit(X_train, y_train)\n",
    "    y_pred = dtr_model.predict(X_val)\n",
    "    score = root_mean_squared_error(y_val, y_pred)\n",
    "    scores.append((d, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5172969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['max_depth', 'score']\n",
    "df_scores = pd.DataFrame(scores, columns=columns)\n",
    "\n",
    "df_scores.sort_values(by='score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3920f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for d in [4, 5, 6]:\n",
    "    for s in [1, 5, 10, 15, 20, 100, 200, 500]:\n",
    "        dtr_model = DecisionTreeRegressor(max_depth=d, min_samples_leaf=s, random_state=1)\n",
    "        dtr_model.fit(X_train, y_train)\n",
    "        y_pred = dtr_model.predict(X_val)\n",
    "        score = root_mean_squared_error(y_val, y_pred)\n",
    "        scores.append((d, s, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cafd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scores, columns=['max_depth', 'min_samples_leaf', 'score']).sort_values(by='score').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 6\n",
    "min_samples_leaf = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_model = DecisionTreeRegressor(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=1)\n",
    "dtr_model.fit(X_train, y_train)\n",
    "y_pred = dtr_model.predict(X_val)\n",
    "dtr_rmse = root_mean_squared_error(y_val, y_pred)\n",
    "dtr_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d65f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_score = dtr_model.predict(X_student)\n",
    "y_test[15], predicted_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fa3a41",
   "metadata": {},
   "source": [
    "Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d15d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for n in range(10, 201, 10):\n",
    "    rf_model = RandomForestRegressor(n_estimators=n, random_state=1)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rf_model.predict(X_val)\n",
    "    score = root_mean_squared_error(y_val, y_pred)\n",
    "    \n",
    "    scores.append((n, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(scores, columns=['n_estimators', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.sort_values(by='score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887ace2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for d in [2, 3, 4, 5, 10, 15, None]:\n",
    "    for n in range(10, 201, 10):\n",
    "        rfr_model = RandomForestRegressor(n_estimators=n,\n",
    "                                    max_depth=d,\n",
    "                                    random_state=1)\n",
    "        rfr_model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = rfr_model.predict(X_val)\n",
    "        score = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "        scores.append((d, n, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ff981",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['max_depth', 'n_estimators', 'score']\n",
    "df_scores = pd.DataFrame(scores, columns=columns)\n",
    "df_scores.sort_values(by='score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8047595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in [2, 3, 4, 5, 10, 15, None]:\n",
    "    df_subset = df_scores[df_scores.max_depth == d]\n",
    "    \n",
    "    plt.plot(df_subset.n_estimators, df_subset.score,\n",
    "             label=f'max_depth={d}')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ecc28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for s in [1, 3, 5, 10, 50]:\n",
    "    for n in range(10, 201, 10):\n",
    "        rfr_model = RandomForestRegressor(n_estimators=n,\n",
    "                                    max_depth=max_depth,\n",
    "                                    min_samples_leaf=s,\n",
    "                                    random_state=1)\n",
    "        rfr_model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = rfr_model.predict(X_val)\n",
    "        score = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "        scores.append((s, n, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0f752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['min_samples_leaf', 'n_estimators', 'score']\n",
    "df_scores = pd.DataFrame(scores, columns=columns)\n",
    "\n",
    "df_scores.sort_values(by='score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584fe8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['black', 'blue', 'orange', 'red', 'grey']\n",
    "values = [1, 3, 5, 10, 50]\n",
    "\n",
    "for s, col in zip(values, colors):\n",
    "    df_subset = df_scores[df_scores.min_samples_leaf == s]\n",
    "    \n",
    "    plt.plot(df_subset.n_estimators, df_subset.score,\n",
    "             color=col,\n",
    "             label=f'min_samples_leaf={s}')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e2f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leaf = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for n in range(10, 201, 10):\n",
    "    rfr_model = RandomForestRegressor(n_estimators=n,\n",
    "                                max_depth=max_depth,\n",
    "                                min_samples_leaf=min_samples_leaf,\n",
    "                                random_state=1)\n",
    "    rfr_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = rfr_model.predict(X_val)\n",
    "    score = root_mean_squared_error(y_val, y_pred)\n",
    "\n",
    "    scores.append((n, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea849f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['n_estimators', 'score']\n",
    "df_scores = pd.DataFrame(scores, columns=columns)\n",
    "\n",
    "df_scores.sort_values(by='score').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997fbc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be57c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_model = RandomForestRegressor(n_estimators=n_estimators,\n",
    "                            max_depth=max_depth,\n",
    "                            min_samples_leaf=min_samples_leaf,\n",
    "                            random_state=1)\n",
    "rfr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfr_model.predict(X_val)\n",
    "rfr_score = root_mean_squared_error(y_val, y_pred)\n",
    "rfr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db9c46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_score = rf_model.predict(X_student)\n",
    "y_test[15], predicted_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c53068",
   "metadata": {},
   "source": [
    "Gradient boosting and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000dae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fd4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(dv.get_feature_names_out())\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "dval = xgb.DMatrix(X_val, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decfa6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89c2d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=10)\n",
    "y_pred = xgb_model.predict(dval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67688dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_mean_squared_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost parameter tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ca9b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(dv.get_feature_names_out())\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe439cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = [(dtrain, 'train'), (dval, 'val')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324e86dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xgb_output(output):\n",
    "    results = []\n",
    "\n",
    "    for line in output.stdout.strip().split('\\n'):\n",
    "        it_line, train_line, val_line = line.split('\\t')\n",
    "\n",
    "        it = int(it_line.strip('[]'))\n",
    "        train = float(train_line.split(':')[1])\n",
    "        val = float(val_line.split(':')[1])\n",
    "\n",
    "        results.append((it, train, val))\n",
    "    \n",
    "    columns = ['num_iter', 'train_auc', 'val_score']\n",
    "    df_results = pd.DataFrame(results, columns=columns)\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f598466",
   "metadata": {},
   "source": [
    "['eta=0.01', 'eta=0.02', 'eta=0.05', 'eta=0.1', 'eta=0.3', 'eta=0.5', 'eta=0.8', 'eta=1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2902d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "eta = 1\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': eta, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=2000,\n",
    "                  verbose_eval=5,\n",
    "                  evals=watchlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80663f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'eta=%s' % (xgb_params['eta'])\n",
    "scores[key] = parse_xgb_output(output)\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a86b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c661a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "etas = [x for x in scores.keys() if x not in ['eta=0.1', 'eta=0.3', 'eta=0.5', 'eta=0.8', 'eta=1']]\n",
    "for eta in etas:\n",
    "    df_scores = scores[eta]\n",
    "    plt.plot(df_scores['num_iter'], df_scores['val_score'], label=eta)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930174ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ec522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f970fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "max_depth = 10\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.01, \n",
    "    'max_depth': max_depth,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=2500,\n",
    "                  verbose_eval=5,\n",
    "                  evals=watchlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74da6cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'max_depth=%s' % (xgb_params['max_depth'])\n",
    "scores[key] = parse_xgb_output(output)\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c640e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44904372",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [x for x in scores.keys() if x not in ['max_depth=10']]\n",
    "for max_depth in max_depths:\n",
    "    df_scores = scores[max_depth]\n",
    "    plt.plot(df_scores['num_iter'], df_scores['val_score'], label=max_depth)\n",
    "# plt.ylim(2.5, 2.7)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cb54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eb37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baacdf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "min_child_weight = 30\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.01, \n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': min_child_weight,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=2500,\n",
    "                  verbose_eval=5,\n",
    "                  evals=watchlist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e4b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'min_child_weight=%s' % (xgb_params['min_child_weight'])\n",
    "scores[key] = parse_xgb_output(output)\n",
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e244ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6616ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_child_weights = [x for x in scores.keys() if x not in []]\n",
    "for min_child_weight in min_child_weights:\n",
    "    df_scores = scores[min_child_weight]\n",
    "    plt.plot(df_scores['num_iter'], df_scores['val_score'], label=min_child_weight)\n",
    "plt.ylim(2.5, 2.7)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51940f",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_child_weight = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3469ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.01, \n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 30,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n",
    "xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=1800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9485893",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb_model.predict(dval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97524b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_rmse = root_mean_squared_error(y_val, y_pred)\n",
    "xgb_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f904988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dstudent = xgb.DMatrix(X_student, feature_names=features)\n",
    "predicted_score = xgb_model.predict(dstudent)\n",
    "y_test[15], predicted_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b3a0cd",
   "metadata": {},
   "source": [
    "Build the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df71cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rmse, dtr_rmse, rfr_score, xgb_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa23c62",
   "metadata": {},
   "source": [
    "The best is: Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f83fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_full_train, y_full_train)\n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "lr_rmse = root_mean_squared_error(y_test, y_pred)\n",
    "lr_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b782ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f725712",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)\n",
    "\n",
    "full_train_dict = df_full_train[categorical + numerical].to_dict(orient='records')\n",
    "X_full_train = dv.transform(full_train_dict)\n",
    "\n",
    "test_dict = df_test[categorical + numerical].to_dict(orient='records')\n",
    "X_test = dv.transform(test_dict)\n",
    "\n",
    "y_full_train = df_full_train['exam_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d00c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_student = df_test.iloc[52]\n",
    "student_dict = df_student[categorical + numerical].to_dict()\n",
    "X_student = dv.transform(student_dict)\n",
    "score_prediction = lr_model.predict(X_student)\n",
    "score_prediction, y_test[52]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc9a22d",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c578f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b5a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    DictVectorizer(), \n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(full_train_dict, y_full_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9ca1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict(student_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe97745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc3e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.bin', 'wb') as f_out:\n",
    "    pickle.dump(pipeline, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a9700",
   "metadata": {},
   "source": [
    "Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "108f1ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('model.bin', 'rb') as f_in:\n",
    "    pipeline = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2fc7dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([62.72703752])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student = {\n",
    "    'hours_studied': 15,\n",
    "    'attendance': 66,\n",
    "    'parental_involvement': 'medium',\n",
    "    'access_to_resources': 'low',\n",
    "    'extracurricular_activities': 'yes',\n",
    "    'sleep_hours': 4,\n",
    "    'previous_scores': 90,\n",
    "    'motivation_level': 'low',\n",
    "    'internet_access': 'yes',\n",
    "    'tutoring_sessions': 2,\n",
    "    'family_income': 'medium',\n",
    "    'teacher_quality': 'high',\n",
    "    'school_type': 'public',\n",
    "    'peer_influence': 'negative',\n",
    "    'physical_activity': 7,\n",
    "    'learning_disabilities': 'no',\n",
    "    'parental_education_level': 'college',\n",
    "    'distance_from_home': 'far',\n",
    "    'gender': 'female'\n",
    "}\n",
    "\n",
    "pipeline.predict(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06840fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
